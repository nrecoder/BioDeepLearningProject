{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04502261-a8b0-4945-8f4a-bf56ed0e7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5437840-90c6-4c57-884f-d7f3f06ccb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8839a984-3ddb-4a2c-a959-806713977045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('S002_whole_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e00311-480c-4733-aaea-9721e4f12293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>BVP</th>\n",
       "      <th>ACC_X</th>\n",
       "      <th>ACC_Y</th>\n",
       "      <th>ACC_Z</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EDA</th>\n",
       "      <th>HR</th>\n",
       "      <th>IBI</th>\n",
       "      <th>Sleep_Stage</th>\n",
       "      <th>Obstructive_Apnea</th>\n",
       "      <th>Central_Apnea</th>\n",
       "      <th>Hypopnea</th>\n",
       "      <th>Multiple_Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>35.53</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.28</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>35.53</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>3.51</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>35.53</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046875</td>\n",
       "      <td>3.02</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>35.53</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>2.94</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>35.53</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013692</th>\n",
       "      <td>31463.937500</td>\n",
       "      <td>120.17</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>78.13</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013693</th>\n",
       "      <td>31463.953125</td>\n",
       "      <td>106.78</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>78.13</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013694</th>\n",
       "      <td>31463.968750</td>\n",
       "      <td>98.52</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>78.13</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013695</th>\n",
       "      <td>31463.984375</td>\n",
       "      <td>95.02</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>78.13</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013696</th>\n",
       "      <td>31464.000000</td>\n",
       "      <td>94.63</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.34</td>\n",
       "      <td>0.143449</td>\n",
       "      <td>78.18</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013697 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TIMESTAMP     BVP  ACC_X  ACC_Y  ACC_Z   TEMP       EDA     HR  \\\n",
       "0            0.000000    5.14   31.0    8.0   55.0  35.53  0.073005  49.00   \n",
       "1            0.015625    4.28   31.0    8.0   55.0  35.53  0.073005  49.00   \n",
       "2            0.031250    3.51   31.0    8.0   55.0  35.53  0.073005  49.00   \n",
       "3            0.046875    3.02   31.0    8.0   55.0  35.53  0.073005  49.00   \n",
       "4            0.062500    2.94   28.0    8.0   55.0  35.53  0.073005  49.00   \n",
       "...               ...     ...    ...    ...    ...    ...       ...    ...   \n",
       "2013692  31463.937500  120.17  -33.0  -24.0   50.0  35.37  0.142168  78.13   \n",
       "2013693  31463.953125  106.78  -33.0  -24.0   50.0  35.37  0.142168  78.13   \n",
       "2013694  31463.968750   98.52  -33.0  -24.0   51.0  35.37  0.142168  78.13   \n",
       "2013695  31463.984375   95.02  -33.0  -24.0   51.0  35.37  0.142168  78.13   \n",
       "2013696  31464.000000   94.63  -33.0  -24.0   50.0  35.34  0.143449  78.18   \n",
       "\n",
       "              IBI Sleep_Stage  Obstructive_Apnea  Central_Apnea  Hypopnea  \\\n",
       "0             NaN           P                NaN            NaN       NaN   \n",
       "1             NaN           P                NaN            NaN       NaN   \n",
       "2             NaN           P                NaN            NaN       NaN   \n",
       "3             NaN           P                NaN            NaN       NaN   \n",
       "4             NaN           P                NaN            NaN       NaN   \n",
       "...           ...         ...                ...            ...       ...   \n",
       "2013692  1.046875           W                NaN            NaN       NaN   \n",
       "2013693  1.046875           W                NaN            NaN       NaN   \n",
       "2013694  1.046875           W                NaN            NaN       NaN   \n",
       "2013695  1.046875           W                NaN            NaN       NaN   \n",
       "2013696  1.046875           W                NaN            NaN       NaN   \n",
       "\n",
       "         Multiple_Events  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "2013692              NaN  \n",
       "2013693              NaN  \n",
       "2013694              NaN  \n",
       "2013695              NaN  \n",
       "2013696              NaN  \n",
       "\n",
       "[2013697 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50ac9c-4e57-418d-9c0c-46c126bfb607",
   "metadata": {},
   "source": [
    "### Initial downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf45105-9784-43e3-9019-2402b133b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = df.iloc[::2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2088fd-a838-4e87-9a08-894d417deed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = df[['TIMESTAMP', 'ACC_X', 'ACC_Y', 'ACC_Z']].iloc[::2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1d0454-5439-4f86-b37b-7bd09882cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_min_df = df[df['TIMESTAMP'] % 300 == 0].reset_index(drop=True)\n",
    "hrtemp_df = five_min_df[['TIMESTAMP', 'TEMP', 'HR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d0d3d1-2de9-4256-8ab3-ee3399998d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.53</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>36.13</td>\n",
       "      <td>72.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600.0</td>\n",
       "      <td>36.23</td>\n",
       "      <td>75.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>72.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>68.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>34.33</td>\n",
       "      <td>82.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>30300.0</td>\n",
       "      <td>34.21</td>\n",
       "      <td>68.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>30600.0</td>\n",
       "      <td>35.16</td>\n",
       "      <td>64.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>30900.0</td>\n",
       "      <td>35.23</td>\n",
       "      <td>64.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>31200.0</td>\n",
       "      <td>35.27</td>\n",
       "      <td>67.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TIMESTAMP   TEMP     HR\n",
       "0          0.0  35.53  49.00\n",
       "1        300.0  36.13  72.10\n",
       "2        600.0  36.23  75.10\n",
       "3        900.0  36.33  72.45\n",
       "4       1200.0  36.00  68.32\n",
       "..         ...    ...    ...\n",
       "100    30000.0  34.33  82.05\n",
       "101    30300.0  34.21  68.62\n",
       "102    30600.0  35.16  64.05\n",
       "103    30900.0  35.23  64.22\n",
       "104    31200.0  35.27  67.97\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrtemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6a8543-3372-4356-b469-0ce41e79764b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>ACC_X</th>\n",
       "      <th>ACC_Y</th>\n",
       "      <th>ACC_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06250</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09375</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006844</th>\n",
       "      <td>31463.87500</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006845</th>\n",
       "      <td>31463.90625</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006846</th>\n",
       "      <td>31463.93750</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006847</th>\n",
       "      <td>31463.96875</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006848</th>\n",
       "      <td>31464.00000</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006849 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIMESTAMP  ACC_X  ACC_Y  ACC_Z\n",
       "0            0.00000   31.0    8.0   55.0\n",
       "1            0.03125   31.0    8.0   55.0\n",
       "2            0.06250   28.0    8.0   55.0\n",
       "3            0.09375   29.0    8.0   55.0\n",
       "4            0.12500   31.0    8.0   53.0\n",
       "...              ...    ...    ...    ...\n",
       "1006844  31463.87500  -33.0  -24.0   50.0\n",
       "1006845  31463.90625  -33.0  -24.0   50.0\n",
       "1006846  31463.93750  -33.0  -24.0   50.0\n",
       "1006847  31463.96875  -33.0  -24.0   51.0\n",
       "1006848  31464.00000  -33.0  -24.0   50.0\n",
       "\n",
       "[1006849 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274af505-935d-4063-9a4e-97a4e0788dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.to_csv('/scratch/npr264/BioDeepL/project/acc_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0b43d2-cbdd-4af2-83f0-e2ee57db5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep stage mapping as before\n",
    "\n",
    "def safe_float(value, default=np.nan):\n",
    "    \"\"\"\n",
    "    Safely converts a value to a float.\n",
    "    If the conversion fails, returns a default value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError):\n",
    "        return np.nan\n",
    "\n",
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label\n",
    "}\n",
    "\n",
    "def forward_fill(x):\n",
    "    \"\"\"\n",
    "    Performs forward fill on a tensor.\n",
    "    If x is 1D (shape [T]), it is temporarily unsqueezed to [T, 1].\n",
    "    Assumes the first value is valid, or fills it with zero if needed.\n",
    "    \"\"\"\n",
    "    single_channel = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single_channel = True\n",
    "\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    if single_channel:\n",
    "        x = x.squeeze(1)\n",
    "    return x\n",
    "\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, x_values ,max_length=2493810,debug=False):\n",
    "        \"\"\" x_values = 'acc' or 'TEMPBVP'\"\"\"\n",
    "        self.subjects = [{} for _ in range(len(subjects_list))]\n",
    "        self.x_values = x_values\n",
    "        if x_values == 'acc':\n",
    "            downsample_freq=32\n",
    "            cols = ['ACC_X', 'ACC_Y', 'ACC_Z']\n",
    "        elif x_values == 'TEMPBVP':\n",
    "            downsample_freq = 0.2\n",
    "            cols = ['TEMP', 'BVP']\n",
    "        else:\n",
    "            print(x_values = 'acc' or 'TEMPBPV')\n",
    "            return\n",
    "        self.downsample = int(64 // downsample_freq)  # Downsample factor\n",
    "        max_length = int(max_length // self.downsample)\n",
    "        self.max_length = max_length\n",
    "            \n",
    "        all_cols = ['TIMESTAMP']+ cols\n",
    "        #print(all_cols)\n",
    "        \n",
    "        for subjectNo, SID in enumerate(subjects_list):\n",
    "            # Load the data for each subject\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    dtype={'Sleep_Stage': 'category'},\n",
    "                    converters=converters,\n",
    "                    low_memory=True\n",
    "                )\n",
    "                if debug:\n",
    "                    print(f\"loaded data for {SID}:\")\n",
    "\n",
    "                # Downsample the data if needed\n",
    "                if self.downsample != 1:\n",
    "                    df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "                    if debug:\n",
    "                        print(f\"After downsampling by factor {self.downsample}, rows: {len(df)}\")\n",
    "                \n",
    "                df = df[df['Sleep_Stage'] != 'P'] # remove data before PSG start\n",
    "                for col in all_cols:\n",
    "                    #print(df.columns)\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                df_X = df[all_cols].copy()\n",
    "                # Normalize the features (z-score normalization per subject)\n",
    "                columns_to_normalize = cols  # Exclude TIMESTAMP\n",
    "                df_X[columns_to_normalize] = (df_X[columns_to_normalize] - df_X[columns_to_normalize].mean()) / df_X[columns_to_normalize].std()\n",
    "                df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "                df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "                \n",
    "                # Pad/truncate the data to the downsampled max_length\n",
    "                if len(df_X) > max_length:\n",
    "                    if debug:\n",
    "                        print(f\"Truncating data for {SID} from {len(df_X)} to {max_length} samples.\")\n",
    "                    df_X = df_X.iloc[:max_length]\n",
    "                    df_Y = df_Y.iloc[:max_length]\n",
    "                else:\n",
    "                    padding_length = max_length - len(df_X)\n",
    "                    padding = pd.DataFrame(np.nan, index=np.arange(padding_length), columns=df_X.columns)\n",
    "                    df_X = pd.concat([df_X, padding], ignore_index=True)\n",
    "                    print(df_X.columns)\n",
    "                    df_Y = pd.concat([df_Y, pd.Series([-1] * padding_length)], ignore_index=True)\n",
    "                self.subjects[subjectNo] = {\n",
    "                    'data': df_X.values.astype(np.float32),  # shape: [T, C]\n",
    "                    'labels': df_Y.to_numpy(),                 # shape: [T]\n",
    "                    'SID': SID\n",
    "                }\n",
    "                if debug:\n",
    "                    print(f\"Data shape for {SID}: {df_X.shape}, Labels shape: {df_Y.shape}\")\n",
    "            else:\n",
    "                warning(f\"File {file_path} does not exist. Skipping subject {SID}.\")\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject = self.subjects[idx]\n",
    "        data = torch.tensor(subject['data'], dtype=torch.float32)\n",
    "        labels = torch.tensor(subject['labels'], dtype=torch.long)\n",
    "\n",
    "        data = forward_fill(data) # fill NaNs with previous values\n",
    "        labels = forward_fill(labels) # fill NaNs with previous values\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9afdbb70-cc13-4ad6-8270-f670c9097eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TIMESTAMP', 'TEMP', 'BVP'], dtype='object')\n",
      "Index(['TIMESTAMP', 'TEMP', 'BVP'], dtype='object')\n",
      "Index(['TIMESTAMP', 'TEMP', 'BVP'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "subject_ids = [\"S002\", \"S003\", \"S004\"]\n",
    "data_directory = \"/scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz\"  \n",
    "demo_dataset = SleepDataset(subjects_list=subject_ids,\n",
    "                                 data_dir=data_directory, x_values='TEMPBVP')\n",
    "\n",
    "# print(\"Total samples in sliding-window dataset:\", len(demo_dataset))\n",
    "# sample, label, sid = demo_dataset[10]\n",
    "# print(f\"Sample shape: {sample.shape} (epoch_samples, num_chans), Label: {label}, Subject ID: {sid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b963b2a-27be-4135-83a1-a4fa8c33357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = demo_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52f086e-26f3-4692-9400-540a150ad369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7817])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bad7438-4f8b-4b72-aa90-5661eca810f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7817, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e00d48-f9c6-4cef-a312-4aa1b874ec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7817])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#soemthing wrong here too need to fix\n",
    "#the bpv and temp should be each their own thing no?\n",
    "data[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1f5c06f-1f1d-408f-a8e8-b586ecf40e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.1762e+03, -2.1243e+00,  1.3196e-01],\n",
       "        [ 9.1812e+03, -2.1069e+00, -7.6298e-03],\n",
       "        [ 9.1862e+03, -2.1243e+00,  1.2635e-01],\n",
       "        ...,\n",
       "        [ 3.1461e+04,  7.3471e-01, -9.3457e-01],\n",
       "        [ 3.1461e+04,  7.3471e-01, -9.3457e-01],\n",
       "        [ 3.1461e+04,  7.3471e-01, -9.3457e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e23425f-76d5-4d6a-8e40-3ff8c84d3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepChunkDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, x_values, chunk_duration=600, chunk_stride=300, debug=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            subjects_list (list): List of subject IDs, e.g. [\"SID1\", \"SID2\", ...].\n",
    "            data_dir (str): Directory where files like \"SID_whole_df.csv\" are stored.\n",
    "            chunk_duration (int): Chunk length in seconds (default 600 s for 10 minutes).\n",
    "            chunk_stride (int): Time in seconds to step forward between chunks (default 300 s, for 50% overlap).\n",
    "            downsample_freq (int): Desired sampling frequency after downsampling (original data are at 64 Hz).\n",
    "            debug (bool): If True, print status messages.\n",
    "        \"\"\"\n",
    "        self.x_values = x_values\n",
    "        if x_values == 'acc':\n",
    "            downsample_freq=32\n",
    "            cols = ['ACC_X', 'ACC_Y', 'ACC_Z']\n",
    "        elif x_values == 'TEMPBVP':\n",
    "            downsample_freq = 0.2\n",
    "            cols = ['TEMP', 'BVP']\n",
    "        else:\n",
    "            print(x_values = 'acc' or 'TEMPBPV')\n",
    "            return\n",
    "        self.downsample = int(64 // downsample_freq)  # Downsample factor\n",
    "            \n",
    "        all_cols = ['TIMESTAMP']+ cols\n",
    "        self.chunks = []  # List to store each generated chunk (with its corresponding data, labels, and SID)\n",
    "        # Effective sampling rate after downsampling becomes downsample_freq Hz.\n",
    "        self.chunk_length = int(chunk_duration * downsample_freq)\n",
    "        self.stride = int(chunk_stride * downsample_freq)\n",
    "\n",
    "        for SID in subjects_list:\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, dtype={'Sleep_Stage': 'category'}, converters=converters, low_memory=True)\n",
    "                if debug:\n",
    "                    print(f\"Loaded data for subject {SID}\")\n",
    "                \n",
    "                # Downsample: every self.downsample-th row\n",
    "                if self.downsample != 1:\n",
    "                    df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "                    if debug:\n",
    "                        print(f\"After downsampling (factor {self.downsample}), rows: {len(df)}\")\n",
    "                \n",
    "                # Remove rows with \"Preparation\" phase if labeled 'P'\n",
    "                df = df[df['Sleep_Stage'] != 'P']\n",
    "\n",
    "                # Ensure numeric conversion for required columns\n",
    "                for col in all_cols:\n",
    "                    #print(df.columns)\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                df_X = df[all_cols].copy()\n",
    "                # Normalize the features (z-score normalization per subject)\n",
    "                columns_to_normalize = cols  # Exclude TIMESTAMP\n",
    "                df_X[columns_to_normalize] = (df_X[columns_to_normalize] - df_X[columns_to_normalize].mean()) / df_X[columns_to_normalize].std()\n",
    "                df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "                df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "                \n",
    "                # Convert features and labels to numpy arrays\n",
    "                data_arr = df_X.values.astype(np.float32)  # shape: [T, C]\n",
    "                labels_arr = df_Y.to_numpy()                # shape: [T]\n",
    "                T = data_arr.shape[0]\n",
    "\n",
    "                # If the record is too short (less than one chunk), pad it with NaNs (-1 for labels)\n",
    "                if T < self.chunk_length:\n",
    "                    pad_size = self.chunk_length - T\n",
    "                    padding_data = np.full((pad_size, data_arr.shape[1]), np.nan, dtype=np.float32)\n",
    "                    data_arr = np.concatenate([data_arr, padding_data], axis=0)\n",
    "                    padding_labels = np.full((pad_size,), -1)\n",
    "                    labels_arr = np.concatenate([labels_arr, padding_labels], axis=0)\n",
    "                    T = self.chunk_length  # update length\n",
    "\n",
    "                # Slide a window over the data with the defined stride to create overlapping chunks\n",
    "                for start in range(0, T - self.chunk_length + 1, self.stride):\n",
    "                    end = start + self.chunk_length\n",
    "                    chunk_data = data_arr[start:end, :]\n",
    "                    chunk_labels = labels_arr[start:end]\n",
    "                    self.chunks.append({\n",
    "                        'data': chunk_data,\n",
    "                        'labels': chunk_labels,\n",
    "                        'SID': SID\n",
    "                    })\n",
    "                if debug:\n",
    "                    num_chunks = (T - self.chunk_length) // self.stride + 1\n",
    "                    print(f\"Subject {SID}: {T} samples processed, generated {num_chunks} chunks\")\n",
    "            else:\n",
    "                print(f\"File {file_path} does not exist. Skipping subject {SID}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        data = torch.tensor(chunk['data'], dtype=torch.float32)\n",
    "        labels = torch.tensor(chunk['labels'], dtype=torch.long)\n",
    "        # Use forward_fill to replace any NaNs with previous values.\n",
    "        data = forward_fill(data)\n",
    "        labels = forward_fill(labels)\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c800dbb-e801-42bc-a9e2-457a78424829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for subject S002\n",
      "After downsampling (factor 319), rows: 6313\n",
      "Subject S002: 4472 samples processed, generated 73 chunks\n",
      "Loaded data for subject S003\n",
      "After downsampling (factor 319), rows: 6433\n",
      "Subject S003: 4989 samples processed, generated 82 chunks\n",
      "Loaded data for subject S004\n",
      "After downsampling (factor 319), rows: 6214\n",
      "Subject S004: 5032 samples processed, generated 82 chunks\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "subject_ids = [\"S002\", \"S003\", \"S004\"]\n",
    "data_directory = \"/scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz\"  \n",
    "demo_dataset = SleepChunkDataset(subjects_list=subject_ids,\n",
    "                                 data_dir=data_directory, x_values='TEMPBVP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9a2d5c2-c015-48a9-a888-076375935d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "82+82+73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e02ddd56-6526-41b6-b36e-dfbbfd0f3fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43ef299c-7476-45f7-93a4-d69e53a6fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = demo_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75e4c41b-c326-4f7d-8940-6840b216e041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo_dataset.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "086420a9-e5f6-4ffe-a0a4-0bd087e9b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dataset.chunks[0]['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51ddf5-c0fe-4004-9c03-e2957835e481",
   "metadata": {},
   "source": [
    "### MULTIFREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f392b5ef-e4d1-46dc-b3b0-9fb1405f3983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418b0c11-33f2-47b2-8572-8ce5205e5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_list = [\"S003\"]\n",
    "data_dir = \"/scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz\"\n",
    "timestamp = False\n",
    "max_length=2493810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475faaf3-299c-49fd-9480-a1bd784a600a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\" x_values = 'acc' or 'TEMPBVP'\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m.subjects = [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(subjects_list))]\n\u001b[32m      3\u001b[39m \u001b[38;5;28mself\u001b[39m.x_values = x_values\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m subjectNo, SID \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(subjects_list):\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Load the data for each subject\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" x_values = 'acc' or 'TEMPBVP'\"\"\"\n",
    "self.subjects = [{} for _ in range(len(subjects_list))]\n",
    "self.x_values = x_values\n",
    "\n",
    "for subjectNo, SID in enumerate(subjects_list):\n",
    "    # Load the data for each subject\n",
    "    file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            dtype={'Sleep_Stage': 'category'},\n",
    "            converters=converters,\n",
    "            low_memory=True\n",
    "        )\n",
    "        if debug:\n",
    "            print(f\"loaded data for {SID}:\")\n",
    "        data_dict = {'acc_data': None, 'tempbvp_data': None}\n",
    "        self.subjects[subjectNo] = {\n",
    "            'data': data_dict,  # shape: [T, C]\n",
    "            'labels': None,                 # shape: [T]\n",
    "            'SID': SID\n",
    "        }\n",
    "        acc_data = getxdata('acc', df)\n",
    "        tempbvp_data = getxdata('TEMPBVP', df)\n",
    "    else:\n",
    "        warning(f\"File {file_path} does not exist. Skipping subject {SID}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d30e00a1-21f4-4a35-a75e-462f29cbaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "def safe_float(value, default=np.nan):\n",
    "    \"\"\"\n",
    "    Safely converts a value to a float.\n",
    "    If the conversion fails, returns a default value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError):\n",
    "        return np.nan\n",
    "\n",
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label\n",
    "}\n",
    "\n",
    "def forward_fill(x):\n",
    "    \"\"\"\n",
    "    Performs forward fill on a tensor.\n",
    "    If x is 1D (shape [T]), it is temporarily unsqueezed to [T, 1].\n",
    "    Assumes the first value is valid, or fills it with zero if needed.\n",
    "    \"\"\"\n",
    "    single_channel = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single_channel = True\n",
    "\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    if single_channel:\n",
    "        x = x.squeeze(1)\n",
    "    return x\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, timestamp = False, max_length=2493810,debug=False):\n",
    "        \"\"\" x_values = 'acc' or 'TEMPBVP'\"\"\"\n",
    "        self.subjects = [{} for _ in range(len(subjects_list))]\n",
    "        #self.x_values = x_values\n",
    "\n",
    "        for subjectNo, SID in enumerate(subjects_list):\n",
    "            # Load the data for each subject\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    dtype={'Sleep_Stage': 'category'},\n",
    "                    converters=converters,\n",
    "                    low_memory=True\n",
    "                )\n",
    "                if debug:\n",
    "                    print(f\"loaded data for {SID}:\")\n",
    "                data_dict = {'acc_data': None, 'tempbvp_data': None}\n",
    "                self.subjects[subjectNo] = {\n",
    "                    'data': data_dict,  # shape: [T, C]\n",
    "                    'labels': None,                 # shape: [T]\n",
    "                    'SID': SID\n",
    "                }\n",
    "                acc_data = self.getxdata('acc', df, subjectNo, max_length)\n",
    "                tempbvp_data = self.getxdata('TEMPBVP', df, subjectNo, max_length)\n",
    "            else:\n",
    "                warning(f\"File {file_path} does not exist. Skipping subject {SID}.\")\n",
    "    def getxdata(self, x_values, df, subjectNo, max_length):\n",
    "        if x_values == 'acc':\n",
    "            downsample_freq=32\n",
    "            cols = ['ACC_X', 'ACC_Y', 'ACC_Z']\n",
    "        elif x_values == 'TEMPBVP':\n",
    "            downsample_freq = 0.2\n",
    "            cols = ['TEMP', 'BVP']\n",
    "        else:\n",
    "            print(x_values = 'acc' or 'TEMPBPV')\n",
    "            return\n",
    "        downsample = int(64 // downsample_freq)  # Downsample factor\n",
    "        max_length = int(max_length // downsample)\n",
    "       #self.max_length = max_length\n",
    "            \n",
    "        all_cols = ['TIMESTAMP']+ cols\n",
    "        #print(all_cols)\n",
    "        \n",
    "        # Downsample the data if needed\n",
    "        if downsample != 1:\n",
    "            df = df.iloc[::downsample].reset_index(drop=True)\n",
    "            # if debug:\n",
    "            #     print(f\"After downsampling by factor {downsample}, rows: {len(df)}\")\n",
    "        df = df[df['Sleep_Stage'] != 'P'] # remove data before PSG start\n",
    "        for col in all_cols:\n",
    "            #print(df.columns)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df_X = df[all_cols].copy()\n",
    "        # Normalize the features (z-score normalization per subject)\n",
    "        columns_to_normalize = cols  # Exclude TIMESTAMP\n",
    "        df_X[columns_to_normalize] = (df_X[columns_to_normalize] - df_X[columns_to_normalize].mean()) / df_X[columns_to_normalize].std()\n",
    "        if x_values == 'TEMPBVP':\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "        \n",
    "        # Pad/truncate the data to the downsampled max_length\n",
    "        if len(df_X) > max_length:\n",
    "            # if debug:\n",
    "            #     print(f\"Truncating data for {SID} from {len(df_X)} to {max_length} samples.\")\n",
    "            df_X = df_X.iloc[:max_length]\n",
    "            if x_values == 'TEMPBVP':\n",
    "                df_Y = df_Y.iloc[:max_length]\n",
    "        else:\n",
    "            padding_length = max_length - len(df_X)\n",
    "            padding = pd.DataFrame(np.nan, index=np.arange(padding_length), columns=df_X.columns)\n",
    "            df_X = pd.concat([df_X, padding], ignore_index=True)\n",
    "            if timestamp == False:\n",
    "                df_X = df_X.drop('TIMESTAMP', axis = 1)\n",
    "            if x_values == 'TEMPBVP':\n",
    "                df_Y = pd.concat([df_Y, pd.Series([-1] * padding_length)], ignore_index=True)\n",
    "                \n",
    "        data = torch.tensor(df_X.values.astype(np.float32), dtype=torch.float32)\n",
    "        data = forward_fill(data)\n",
    "        if x_values == 'TEMPBVP':\n",
    "            self.subjects[subjectNo]['data']['tempbvp_data'] = data\n",
    "            self.subjects[subjectNo]['labels'] = df_Y.to_numpy()\n",
    "        elif x_values == 'acc':\n",
    "            self.subjects[subjectNo]['data']['acc_data'] = data\n",
    "            # if debug:\n",
    "            #     print(f\"Data shape for {SID}: {df_X.shape}, Labels shape: {df_Y.shape}\")        \n",
    "    def downsamplelabels(self, labels):\n",
    "        #not sure if i even need this at least for the not chunk part\n",
    "        samples_per_label = 32*5\n",
    "        # Compute mode for every 5 seconds\n",
    "        dataset_size = labels.shape[0]\n",
    "        num_full_chunks = dataset_size // samples_per_label  # Number of complete 9600-sized chunks\n",
    "        remainder_size = dataset_size % samples_per_label  # Remaining elements after full chunks\n",
    "        \n",
    "        modes = torch.tensor([\n",
    "            torch.bincount(labels[i:i+samples_per_label]).argmax().item()\n",
    "            for i in range(0, num_full_chunks * samples_per_label, samples_per_label)\n",
    "        ])\n",
    "        \n",
    "        # Handle the remaining portion separately (if it exists)\n",
    "        if remainder_size > 0:\n",
    "            remainder_mode = torch.bincount(labels[num_full_chunks * samples_per_label:]).argmax()\n",
    "            modes = torch.cat([modes, remainder_mode.unsqueeze(0)])\n",
    "        return modes\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject = self.subjects[idx]\n",
    "        #I THINK YOU SHOULD DO THE TENSORING AND FWD FILL EARLIER SO HERE ITS JUST A PULL \n",
    "        data = subject['data']\n",
    "        #high_freq_labels = torch.tensor(subject['labels'], dtype=torch.long)\n",
    "        #labels = self.downsamplelabels(high_freq_labels)\n",
    "        #data = forward_fill(data) # fill NaNs with previous values\n",
    "        #labels = forward_fill(labels) # fill NaNs with previous values\n",
    "\n",
    "        labels = subject['labels']\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d7a9f00-48b9-43d2-b9bd-f614ce3042f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "subject_ids = [\"S002\", \"S003\"]\n",
    "data_directory = \"/scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz\"  \n",
    "demo_dataset = SleepDataset(subjects_list=subject_ids,\n",
    "                                 data_dir=data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b47cf457-e565-4cfc-aa69-7685c93912ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = demo_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4efd1efb-e3c9-432f-bd19-e7bd5b04568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1246905, 3]), torch.Size([7817, 2]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['acc_data'].shape,data['tempbvp_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66000abe-711c-4c2e-89c1-43048d230c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7817,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba7ca107-370c-4018-93b5-e1080f3b63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepChunkDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, chunk_duration=600, chunk_stride=300, timestamp = False, debug=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            subjects_list (list): List of subject IDs, e.g. [\"SID1\", \"SID2\", ...].\n",
    "            data_dir (str): Directory where files like \"SID_whole_df.csv\" are stored.\n",
    "            chunk_duration (int): Chunk length in seconds (default 600 s for 10 minutes).\n",
    "            chunk_stride (int): Time in seconds to step forward between chunks (default 300 s, for 50% overlap).\n",
    "            downsample_freq (int): Desired sampling frequency after downsampling (original data are at 64 Hz).\n",
    "            debug (bool): If True, print status messages.\n",
    "        \"\"\"\n",
    "        #self.x_values = x_values\n",
    "        self.chunks = []  # List to store each generated chunk (with its corresponding data, labels, and SID)\n",
    "        # Effective sampling rate after downsampling becomes downsample_freq Hz.\n",
    "        \n",
    "\n",
    "        for SID in subjects_list:\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, dtype={'Sleep_Stage': 'category'}, converters=converters, low_memory=True)\n",
    "                if debug:\n",
    "                    print(f\"Loaded data for subject {SID}\")\n",
    "\n",
    "                acc_chunk_data = self.getxdata('acc',chunk_duration, chunk_stride,df,max_length, SID, timestamp)\n",
    "                # acc_chunk_data = forward_fill(torch.tensor(acc_chunk_data, dtype=torch.float32))\n",
    "                tempbvp_chunk_data, chunk_labels, SIDs = self.getxdata('TEMPBVP',chunk_duration, chunk_stride,df,max_length, SID, timestamp)\n",
    "                # tempbvp_chunk_data = forward_fill(torch.tensor(tempbvp_chunk_data, dtype=torch.float32))\n",
    "                # chunk_labels = forward_fill(torch.tensor(chunk_labels,dtype = torch.long))\n",
    "                # print(acc_chunk_data.shape)\n",
    "                # print(tempbvp_chunk_data.shape)\n",
    "                # print(chunk_labels.shape)\n",
    "                for acc, tempbvp, labels, SIDS in zip(acc_chunk_data,tempbvp_chunk_data, chunk_labels, SIDs):\n",
    "                    chunk_data = {'acc_data': acc, 'tempbvp_data': tempbvp}\n",
    "                    self.chunks.append({\n",
    "                            'data': chunk_data,\n",
    "                            'labels': labels,\n",
    "                            'SID': SID\n",
    "                        })\n",
    "            else:\n",
    "                print(f\"File {file_path} does not exist. Skipping subject {SID}\")\n",
    "    def getxdata(self, x_values, chunk_duration, chunk_stride, df, max_length, SID, timestamp = timestamp, debug = False):\n",
    "        if x_values == 'acc':\n",
    "            downsample_freq=32\n",
    "            cols = ['ACC_X', 'ACC_Y', 'ACC_Z']\n",
    "        elif x_values == 'TEMPBVP':\n",
    "            downsample_freq = 0.2\n",
    "            cols = ['TEMP', 'BVP']\n",
    "        else:\n",
    "            print(x_values = 'acc' or 'TEMPBPV')\n",
    "            return\n",
    "        all_cols = ['TIMESTAMP']+ cols\n",
    "        downsample = int(64 // downsample_freq)  # Downsample factor\n",
    "        chunk_length = int(chunk_duration * downsample_freq)\n",
    "        stride = int(chunk_stride * downsample_freq)\n",
    "        # Downsample: every self.downsample-th row\n",
    "        if downsample != 1:\n",
    "            df = df.iloc[::downsample].reset_index(drop=True)\n",
    "            if debug:\n",
    "                print(f\"After downsampling (factor {downsample}), rows: {len(df)}\")\n",
    "        \n",
    "        # Remove rows with \"Preparation\" phase if labeled 'P'\n",
    "        df = df[df['Sleep_Stage'] != 'P']\n",
    "\n",
    "        # Ensure numeric conversion for required columns\n",
    "        for col in all_cols:\n",
    "            #print(df.columns)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        df_X = df[all_cols].copy()\n",
    "        # Normalize the features (z-score normalization per subject)\n",
    "        columns_to_normalize = cols  # Exclude TIMESTAMP\n",
    "        df_X[columns_to_normalize] = (df_X[columns_to_normalize] - df_X[columns_to_normalize].mean()) / df_X[columns_to_normalize].std()\n",
    "\n",
    "        if x_values == 'TEMPBVP':\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "            labels_arr = df_Y.to_numpy()                # shape: [T]\n",
    "        if timestamp == False:\n",
    "            df_X = df_X.drop('TIMESTAMP', axis = 1)\n",
    "        \n",
    "        # Convert features and labels to numpy arrays\n",
    "        data_arr = df_X.values.astype(np.float32)  # shape: [T, C]\n",
    "        T = data_arr.shape[0]\n",
    "\n",
    "        # If the record is too short (less than one chunk), pad it with NaNs (-1 for labels)\n",
    "        if T < chunk_length:\n",
    "            pad_size = chunk_length - T\n",
    "            padding_data = np.full((pad_size, data_arr.shape[1]), np.nan, dtype=np.float32)\n",
    "            data_arr = np.concatenate([data_arr, padding_data], axis=0)\n",
    "            padding_labels = np.full((pad_size,), -1)\n",
    "            if x_values == 'TEMPBVP':\n",
    "                labels_arr = np.concatenate([labels_arr, padding_labels], axis=0)\n",
    "            T = self.chunk_length  # update length\n",
    "\n",
    "        # Slide a window over the data with the defined stride to create overlapping chunks\n",
    "        chunk_data_list = []\n",
    "        chunk_labels_list = []\n",
    "        SIDS_list = []\n",
    "        for start in range(0, T - chunk_length + 1, stride):\n",
    "            end = start + chunk_length\n",
    "            chunk_data = torch.tensor(data_arr[start:end, :], dtype = torch.float32)\n",
    "            if x_values == 'TEMPBVP':\n",
    "                chunk_labels = torch.tensor(labels_arr[start:end], dtype=torch.long)\n",
    "            # self.chunks.append({\n",
    "            #     'data': chunk_data,\n",
    "            #     'labels': chunk_labels,\n",
    "            #     'SID': SID\n",
    "            # })\n",
    "            chunk_data_list.append(forward_fill(chunk_data))\n",
    "            if x_values == 'TEMPBVP':\n",
    "                chunk_labels_list.append(forward_fill(chunk_labels))\n",
    "                SIDS_list.append(SID)\n",
    "        if debug:\n",
    "            num_chunks = (T - chunk_length) // self.stride + 1\n",
    "            print(f\"Subject {SID}: {T} samples processed, generated {num_chunks} chunks\")\n",
    "        if x_values == 'acc':\n",
    "            return chunk_data_list\n",
    "        elif x_values == 'TEMPBVP':\n",
    "            return chunk_data_list, chunk_labels_list, SIDS_list\n",
    "    def downsamplelabels(self, labels):\n",
    "        #may need work\n",
    "        samples_per_label = 32*5\n",
    "        # Compute mode for every 5 seconds elements\n",
    "        dataset_size = labels.shape[0]\n",
    "        num_full_chunks = dataset_size // samples_per_label  # Number of complete 9600-sized chunks\n",
    "        remainder_size = dataset_size % samples_per_label  # Remaining elements after full chunks\n",
    "        \n",
    "        modes = torch.tensor([\n",
    "            torch.bincount(labels[i:i+samples_per_label]).argmax().item()\n",
    "            for i in range(0, num_full_chunks * samples_per_label, samples_per_label)\n",
    "        ])\n",
    "        \n",
    "        # Handle the remaining portion separately (if it exists)\n",
    "        if remainder_size > 0:\n",
    "            remainder_mode = torch.bincount(labels[num_full_chunks * samples_per_label:]).argmax()\n",
    "            modes = torch.cat([modes, remainder_mode.unsqueeze(0)])\n",
    "        return modes\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        # data = torch.tensor(chunk['data'], dtype=torch.float32)\n",
    "        # labels = torch.tensor(chunk['labels'], dtype=torch.long)\n",
    "        data = chunk['data']\n",
    "        labels = chunk['labels']\n",
    "        # labels = self.downsamplelabels(high_freq_labels)\n",
    "        #data = forward_fill(data)\n",
    "        #labels = forward_fill(labels)\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7562ce12-a592-4943-abbb-e916155e58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "subject_ids = [\"S002\", \"S003\"]\n",
    "data_directory = \"/scratch/npr264/BioDeepL/dreamt/physionet.org/files/dreamt/2.0.0/data_64Hz\"  \n",
    "demo_dataset = SleepChunkDataset(subjects_list=subject_ids,\n",
    "                                 data_dir=data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "963a5a8e-405b-4b2f-bda0-dd31a44c65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = demo_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "209049fa-0ff3-44a5-8de9-562f0d85a550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19200, 3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['acc_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0cf907a-0666-4a1e-ba28-816fc4186b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 2])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tempbvp_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6d1f182-62fb-4e06-b4db-9fbca29949a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e61e3-12ef-4837-a576-9995ea507bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
